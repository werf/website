---
title: Инициализация БД и миграции
permalink: rails/200_real_apps/40_db_init_and_migrations.html
layout: wip
examples: examples/rails/100_db_init_and_migrations
examples_initial: examples/rails/100_logging {% comment %}FIX: change the initial folder to hello world{% endcomment %}
description: |
  В этой главе мы рассмотрим наиболее корректные способы выполнять подготовку базы данных приложения к работе.
---

## Инициализация/миграции БД в отдельной Job

Ранее подготовку БД мы выполняли прямо перед запуском приложения, и в том же контейнере, в котором запускалось и само приложение. Но корректнее было бы выполнять подготовку БД единожды при деплое новых версий приложения.
Это поможет нам:
* проще контролировать подготовку БД к работе;
* проще отлаживать подготовку БД при возникновении проблем;
* избавиться от выполнения инициализации/миграций БД снова и снова при создании Pod'ов и перезапуске контейнеров;
* избавиться от потенциальных проблем, связанных с параллельным выполнением множественных инициализаций и миграций;
* перестраховать нас от запуска инициализации/миграций в контейнерах с разными версиями приложения, что может возникать даже при стандартной стратегии обновления Deployment'ов приложений.

Иначе говоря, запуск инициализации и миграций БД только один раз перед обновлением приложения — наиболее масштабируемый, простой и безопасный способ подготовки БД к работе.

Для того, чтобы запускать подготовку БД только один раз при каждом деплое, мы вынесем команду подготовки БД из контейнера самого приложения в отдельную Job. В init-контейнере нашей Job мы будем дожидаться готовности базы данных:
{% include_file "{{ page.examples | append: "/.helm/templates/setup-and-migrate-db-job.yaml" }}" snippet="wait-db-container" syntax="yaml" %}

И только потом, после выполнения всех init-контейнеров, в основном контейнере Job мы запустим подготовку БД:
{% include_file "{{ page.examples | append: "/.helm/templates/setup-and-migrate-db-job.yaml" }}" snippet="prepare-db-container" syntax="yaml" %}

В итоге получим такую Job:
{% include snippetcut_example path=".helm/templates/setup-and-migrate-db-job.yaml" syntax="yaml" examples=page.examples %}

## Убираем подготовку БД из Deployment'а приложения

Так как теперь подготовка БД у нас происходит в Job, то нам потребуется убрать команды подготовки БД из команды запуска самого приложения. Также нам потребуется удалить команду `mysqladmin ping`, которую мы использовали для того, чтобы перед началом инициализации/миграций дожидаться развертывания БД.

Было:
{% include_file "{{ page.examples_initial | append: "/.helm/templates/deployment.yaml" }}" snippet="app-command" syntax="yaml" %}

Стало:
{% include_file "{{ page.examples | append: "/.helm/templates/deployment.yaml" }}" snippet="app-command" syntax="yaml" %}

Вместо команды `mysqladmin ping` добавим в Deployment init-контейнер, который будет ждать завершения Job, таким образом задерживая запуск контейнера приложения до того момента, пока подготовка БД не будет завершена:
{% include_file "{{ page.examples | append: "/.helm/templates/deployment.yaml" }}" snippet="wait-prepare-db-container" syntax="yaml" %}

В конечном итоге Deployment нашего приложения станет выглядеть так:
{% include snippetcut_example path=".helm/templates/deployment.yaml" syntax="yaml" examples=page.examples %}

## Настройка доступа к Kubernetes изнутри контейнеров

Прямо изнутри контейнеров вы можете связываться с Kubernetes через домен `kubernetes.default.svc`. Утилита `kubectl`, запущенная внутри контейнера, автоматически начинает работать с кластером Kubernetes через этот домен. Но по умолчанию ServiceAccount, из под которого запущен контейнер, не хватит прав для доступа к Kubernetes API. Чтобы исправить это, нам потребуется добавить нашему ServiceAccount прав на доступ к кластеру:
{% include snippetcut_example path=".helm/templates/roles.yaml" syntax="yaml" examples=page.examples %}

## Развертывание

Попробуем задеплоить наше обновленное приложение:

```shell
werf converge --dev --repo <имя пользователя Docker Hub>/werf-guided-rails
```

Результат успешного развертывания:

```shell
│   ...
│ ┌ Status progress
│ │ DEPLOYMENT                                                            REPLICAS     AVAILABLE     UP-TO-DATE
│ │ basicapp                                                              3->2/2       2             2
│ │ │   POD                       READY    RESTARTS     STATUS
│ │ ├── 5797996bd4-kff9r          1/1      0            Running
│ │ ├── 5797996bd4-lp6wk          1/1      0            Init:0/1 ->
│ │ │                                                   Running
│ │ ├── 6d946db68c-6h2zt          1/1      0            Terminating
│ │ └── 6d946db68c-7dlnt          1/1      1            Running ->
│ │                                                     Terminating
│ │ STATEFULSET                                                           REPLICAS     READY         UP-TO-DATE
│ │ mysql                                                                 1/1          1             1                    ↵
│ │
│ │ JOB                                                                   ACTIVE       DURATION      SUCCEEDED/FAILED
│ │ setup-and-migrate-db-rev2                                             0            7s            1/0
│ │ │   POD                       READY    RESTARTS     STATUS
│ │ └── and-migrate-db-rev2-qzmhz 0/1      0            Completed
│ └ Status progress
└ Waiting for release resources to become ready (12.38 seconds)
Release "werf-guided-rails" has been upgraded. Happy Helming!
```

## Как это работает?

`werf converge` создает все ресурсы одновременно: StatefulSet для БД, Deployment для приложения и Job для подготовки базы. Но, несмотря на то, что ресурсы создаются одновременно, основные команды, которые должны выполниться в этих ресурсах, будут иметь очередность:
1. Сначала (пере)развернется база данных, разворачиваемая StatefulSet'ом — этому ничто не препятствует.
2. После развертывания БД выполнится Job для инициализации базы данных и миграций. Отследить и дождаться успешного развертывания БД нашей Job помогает команда `kubectl rollout status`.
3. И уже после выполнения этой Job запускаются наши приложения. Успешное завершение Job им помогает отследить команда `kubectl wait`.

Таким образом выставляется очередность операций во время деплоя. Если бы её не было, то в части случаев подготовка БД не смогла бы выполниться, т.к. БД начала бы перезапускаться в тот же момент, в который инициализация/миграции БД попытались бы выполниться. Также и приложение не смогло бы заработать, так как во время его запуска и БД может быть недоступна, и миграции могут быть не выполнены.

## Использование базы данных, развернутой вне Kubernetes

Наша Job ожидает доступности базы данных используя команду `kubectl rollout status`. Если же наша БД развернута за пределами нашего кластера Kubernetes, то нам понадобится другой способ проверять её готовность. Базы данных обычно имеют свои собственные утилиты для проверки своей доступности. Для MySQL это `mysqladmin ping`, который мы уже использовали в предыдущих главах. Обычно его использование выглядит так:

```shell
until mysqladmin -h mysql -P 3306 -u root -p=password ping; do
  sleep 1
done
```

Это команда должна будет использоваться в Job вместо команды `kubectl rollout status`.

## Проверка доступности базы в Kubernetes без kubectl

Стоит упомянуть, что доступность базы в кластере Kubernetes также можно проверять с помощью утилит вроде `mysqladmin ping`, без использования `kubectl`. Но в таком случае вызов `mysqladmin ping` нужно несколько доработать.

{% offtopic title="Зачем дорабатывать?" %}
При переподнятии базы (например, при обновлении её StatefulSet), базе потребуется некоторое время на то, чтобы завершить работу, а потом некоторое время на то, чтобы снова её возобновить. Таким образом, если мы проверим доступность базы только единожды перед выполнением инициализации/миграций, то мы можем попасть на тот момент, когда база завершает работу, но ещё не завершила. После чего, во время запуска инициализации/миграций, база может окончательно завершить работу и оказаться временно недоступной.

Решить это можно, если считать базу данных доступной, только если команда `mysqladmin ping` успешно выполнилась несколько раз подряд.
{% endofftopic %}

Будем считать БД доступной только после 7 успешно выполненных команд `mysqladmin ping` подряд, с интервалом между повторными запусками `mysqladmin ping` в 2 секунды:

```yaml
command:
- sh
- -euc
- |
  $success_threshold=7

  is_mysql_available() {
    i=0
    while [ $i -lt $success_threshold ]; do
      mysqladmin -h mysql -P 3306 -u root -p=password ping || return 1
      i=$((i+1))
      sleep 2
    done
  }

  until is_mysql_available; do
    sleep 2
  done
```

Таким способом база данных должна быть доступна 14 секунд подряд, прежде чем мы начнем выполнять инициализацию/миграции базы данных. Это поможет нам убедиться не только в том, что база данных доступна прямо сейчас, но и в том, что база данных перезапустилась, если ей требовался перезапуск.

## Helm Hooks как альтернативный способ задавать очередность деплоя

Соблюдать очередность между запуском БД, подготовкой БД и запуском приложения можно также с помощью Helm Hooks. В таком случае Job для подготовки БД должна быть обычной Job при первом деплое, но становиться Helm Hook при повторных деплоях. Сделать это можно так:

{% raw %}
```yaml
kind: Job
metadata:
  annotations:
    # Если повторный деплой, то добавить аннотацию, которая сделает Helm Hook из этой Job.
    {{- if $.Release.IsUpgrade }}
    helm.sh/hook: "pre-upgrade"
    {{- end }}
```
{% endraw %}

При первом деплое это будет обычная Job, которая запустится одновременно с приложением и базой данных. Очередность выполнения на этом этапе обеспечивается стандартными вышеупомянутыми способами — через `mysqladmin ping`, `kubectl wait`, `kubectl rollout status` и др.

При повторных деплоях эта Job будет удалена, а вместо неё будет запускаться Helm Hook. Helm Hook от Job по сути ничем отличаться не будет, кроме того, что Helm Hook будет выполняться _перед_ деплоем основных ресурсов, а не одновременно с деплоем. Таким образом мы сможем убедиться, что инициализация/миграции БД не запущены одновременно с обновлением базы данных или обновлением приложения, а выполнены заранее.

В Helm Hook вы можете обойтись без `mysqladmin ping` и `kubectl rollout status`, а вот в Deployment ожидание завершения Job с `kubectl wait` нужно заменить на ожидание деплоя самой базы данных с помощью `kubectl rollout status` или `mysqladmin ping`. Из Deployment'а выполнение Job дожидаться более не нужно, т.к. то, что делала Job, теперь всегда будет выполняться до обновления Deployment.
