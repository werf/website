### Требования

- CI-система;

- Kubernetes для запуска CI-задач с установленным Kubernetes Runner вашей CI-системы.

### Настройка Runner'а

Настройте Kubernetes Runner вашей CI-системы так, чтобы создаваемые им Pod'ы имели следующую конфигурацию:

```yaml
apiVersion: v1
kind: Pod
metadata:
  namespace: ci
  annotations:
    "container.apparmor.security.beta.kubernetes.io/build": unconfined
spec:
  securityContext:
    runAsNonRoot: true
    runAsUser: 1000
    runAsGroup: 1000
    fsGroup: 1000
```

Если нужно кеширование `.werf` (рекомендуется), то Pod'ы должны иметь дополнительную конфигурацию:

```yaml
spec:
  containers:
  - volumeMounts:
    - name: werf-cache
      mountPath: /home/build/.werf
  volumes:
  - name: werf-cache
    persistentVolumeClaim:
      claimName: ci-kubernetes-runner-werf-cache
```

... а если кеширование не нужно, то пусть имеют эту конфигурацию:

```yaml
spec:
  containers:
  - volumeMounts:
    - name: werf-cache
      mountPath: /home/build/.werf
  volumes:
  - name: werf-cache
    emptyDir: {}
```

Если будете развертывать приложения с werf в тот же кластер, в котором запускается Kubernetes Runner, то добавьте эту конфигурацию:

```yaml
spec:
  serviceAccountName: ci-kubernetes-runner
```

### Настройка Kubernetes

Если в конфигурации Kubernetes Runner'а вы включили кеширование `.werf`, то создайте в кластере соответствующий PersistentVolumeClaim, например:

```shell
kubectl create -f - <<EOF
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: ci-kubernetes-runner-werf-cache
  namespace: ci
spec:
  accessModes:
    - ReadWriteMany
  resources:
    requests:
      storage: 10Gi
EOF
```

Если будете развертывать приложения в тот же кластер, в котором запускается Kubernetes Runner, то в кластере для запуска CI-задач настройте RBAC следующей командой:

```shell
kubectl create -f - <<EOF
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: ci-kubernetes-runner
  namespace: ci
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: ci-kubernetes-runner
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: cluster-admin
subjects:
  - kind: ServiceAccount
    name: ci-kubernetes-runner
    namespace: ci
EOF
```

> Для большей безопасности можете создать более ограниченную ClusterRole/Role и использовать её вместо кластерной роли `cluster-admin` выше.

Если Kubernetes-узлы для Kubernetes Runner'а имеют ядро Linux версии 5.12 или ниже, то разрешите в этом кластере использование FUSE для Kubernetes Runner следующей командой:

```shell
kubectl create -f - <<EOF
---
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: fuse-device-plugin
  namespace: kube-system
spec:
  selector:
    matchLabels:
      name: fuse-device-plugin
  template:
    metadata:
      labels:
        name: fuse-device-plugin
    spec:
      hostNetwork: true
      containers:
      - image: soolaugust/fuse-device-plugin:v1.0
        name: fuse-device-plugin-ctr
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop: ["ALL"]
        volumeMounts:
          - name: device-plugin
            mountPath: /var/lib/kubelet/device-plugins
      volumes:
        - name: device-plugin
          hostPath:
            path: /var/lib/kubelet/device-plugins
---
apiVersion: v1
kind: LimitRange
metadata:
  name: enable-fuse
  namespace: ci
spec:
  limits:
  - type: "Container"
    default:
      github.com/fuse: 1
EOF
```

### Конфигурация container registry

[Включите сборщик мусора]({{ "/documentation/v1.2/usage/cleanup/cr_cleanup.html#%D1%81%D0%B1%D0%BE%D1%80%D1%89%D0%B8%D0%BA-%D0%BC%D1%83%D1%81%D0%BE%D1%80%D0%B0-container-registry" | relative_url }}) вашего container registry.

### Подготовка кластера Kubernetes к мультиплатформенной сборке (опционально)

> Данный шаг требуется только для сборки образов для платформ, отличных от платформы системы, где запущен werf.

Регистрируем на узлах Kubernetes эмуляторы с помощью образа qemu-user-static:

```shell
kubectl create -f - <<EOF
---
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: qemu-user-static
  labels:
    app: qemu-user-static
spec:
  selector:
    matchLabels:
      name: qemu-user-static
  template:
    metadata:
      labels:
        name: qemu-user-static
    spec:
      initContainers:
        - name: qemu-user-static
          image: multiarch/qemu-user-static
          args: ["--reset", "-p", "yes"]
          securityContext:
            privileged: true
      containers:
        - name: pause
          image: gcr.io/google_containers/pause
          resources:
            limits:
              cpu: 50m
              memory: 50Mi
            requests:
              cpu: 50m
              memory: 50Mi
EOF
```
