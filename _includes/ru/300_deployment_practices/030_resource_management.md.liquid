В этом разделе мы покажем, как управлять ресурсами приложений в Kubernetes.

## Приоритет

`priorityClassName` влияет на то, какие Pod'ы будут schedule'иться в первую очередь, а также на то, какие Pod'ы могут быть «вытеснены» (evicted) планировщиком, если места для новых Pod'ов на узлах не осталось.

Потребуется создать несколько ресурсов типа PriorityClass и ассоциировать их с Pod'ами через `priorityClassName`. Набор PriorityClass'ов может выглядеть примерно так:

* *Cluster*. `Priority > 10000`. Критичные для функционирования кластера компоненты, такие как kube-apiserver.
* *Daemonsets*. `Priority: 10000`. Обычно мы хотим, чтобы Pod'ы DaemonSet'ов не вытеснялись с узлов обычными приложениями.
* *Production-high*. `Priority: 9000`. Stateful-приложения.
* *Production-medium*. `Priority: 8000`. Stateless-приложения.
* *Production-low*. `Priority: 7000`. Менее критичные приложения.
* *Default*. `Priority: 0`. Приложения для окружений не категории production.

Это предохранит нас от внезапных evict'ов важных компонентов и позволит более важным приложениям вытеснять менее важные при недостатке узлов.

## Резервирование ресурсов

Планировщик на основании `resources.requests` Pod'а принимает решение о том, на каком узле этот Pod запустить. К примеру, Pod не будет schedule'иться на узел, на котором свободных (т. е. *non-requested*) ресурсов недостаточно, чтобы удовлетворить запросам (*requests*) нового Pod'а. А `resources.limit` позволяют ограничить потребление ресурсов Pod'ами, которые начинают расходовать ощутимо больше, чем ими было запрошено через requests. **Лучше устанавливать лимиты равные запросам**, так как если указать лимиты сильно выше, чем запросы, то это может лишить другие Pod'ы узла выделенных для них ресурсов. Это может приводить к выводу из строя других приложений на узле или даже самого узла. Также схема ресурсов Pod'а присваивает ему определенный [QoS class](https://kubernetes.io/docs/tasks/configure-pod-container/quality-service-pod): например, он влияет на порядок, в котором Pod'ы будут вытесняться (evicted) с узлов.

Поэтому **необходимо выставлять и запросы, и лимиты и для CPU, и для памяти**. Единственное, что можно/нужно опустить, так это CPU-лимит, если [версия ядра Linux ниже 5.4](https://habr.com/ru/company/flant/blog/489668/#comment_21485436) (для EL7/CentOS7 версия ядра должна быть ниже `3.10.0-1062.8.1.el7`).

>Подробнее о том, что такое requests и limits, какие бывают QoS-классы в Kubernetes, можно почитать в [этой статье](https://habr.com/ru/company/flant/blog/459326/).

Также некоторые приложения имеют свойство бесконтрольно расти в потреблении оперативной памяти: к примеру, Redis, использующийся для кэширования, или же приложение, которое «течёт» просто само по себе. Чтобы ограничить их влияние на остальные приложения на том же узле, им можно и нужно устанавливать лимит на количество потребляемой памяти. Проблема только в том, что, при достижении этого лимита приложение будет получать сигнал KILL. Приложения не могут ловить/обрабатывать этот сигнал и, вероятно, не смогут корректно завершаться. Поэтому **очень желательно использовать специфичные для приложения механизмы контроля за потреблением памяти** в дополнение к лимитам Kubernetes, и не доводить эффективное потребление памяти приложением до `limits.memory` Pod'а.

Конфигурация для Redis, которая поможет с этим:

```shell
maxmemory 500mb   # если данные начнут занимать 500 Мб...
maxmemory-policy allkeys-lru   # ...Redis удалит редко используемые ключи
```

А для Sidekiq это может быть [Sidekiq worker killer](https://github.com/klaxit/sidekiq-worker-killer):

```shell
require 'sidekiq/worker_killer'
Sidekiq.configure_server do |config|
  config.server_middleware do |chain|
    # Корректно завершить Sidekiq при достижении им потребления в 500 Мб
    chain.add Sidekiq::WorkerKiller, max_rss: 500
  end
end
```

Понятное дело, что во всех этих случаях `limits.memory` должен быть выше, чем пороги срабатывания вышеуказанных механизмов.

Далее мы рассмотрим использование `VerticalPodAutoscaler` для автоматического выставления ресурсов.
