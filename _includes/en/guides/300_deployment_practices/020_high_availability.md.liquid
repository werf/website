In this section, we will show you what features and settings Kubernetes should pay attention to in order to ensure high availability of your applications running in K8s.

## Number of replicas

You need at least two replicas for the application to be considered minimally available. But why, you may ask, is a single replica not enough? The problem is that many entities in Kubernetes (Node, Pod, ReplicaSet, etc.) are ephemeral, i.e. under certain conditions, they may be automatically deleted/recreated. Obviously, the Kubernetes cluster and applications running in it must account for that.

For example, when the autoscaler scales down your number of nodes, some of those nodes will be deleted, including the Pods running on them. If the sole instance of your application is running on one of the nodes to be deleted, you may find your application completely unavailable, though this is usually short-lived. In general, if you only have one replica of the application, any abnormal termination of it will result in downtime. In other words, you must have **at least two running replicas of the application**.

The more replicas there are, the milder of a decline there will be in your application’s computing capacity in the event that some replica fails. For example, suppose you have two replicas and one fails due to network issues on a node. The load that the application can handle will be cut in half (with only one of the two replicas available). Of course, the new replica will be scheduled on a new node, and the load capacity of the application will be fully restored. But until then, increasing the load can lead to service disruptions, which is why you **must have some replicas in reserve**

*The above recommendations are relevant to cases in which there is no HorizontalPodAutoscaler used. The best alternative for applications that have more than a few replicas is to configure HorizontalPodAutoscaler and let it manage the number of replicas. We will focus on HorizontalPodAutoscaler in the next article.*

## The update strategy

The default update strategy for Deployment entails a reduction of the number of old+new ReplicaSet Pods with a `Ready` status of 75% of their pre-update amount. Thus, during the update, the computing capacity of an application may drop to 75% of its regular level, and that may lead to a partial failure (degradation of the application’s performance). The `strategy.RollingUpdate.maxUnavailable` parameter allows you to configure the maximum percentage of Pods that can become unavailable during an update. Therefore, either make sure that your application runs smoothly even in the event that 25% of your Pods are unavailable or lower the `maxUnavailable` parameter. Note that the `maxUnavailable` parameter is rounded down.

There’s a little trick to the default update strategy (`RollingUpdate`): the application will temporarily have not only a few replicas, but two different versions (the old one and the new one) running concurrently as well. Therefore, if running different replicas and different versions of the application side by side is unfeasible for some reason, then you can use `strategy.type: Recreate`. Under the `Recreate` strategy, all the existing Pods are killed before the new Pods are created. This results in a short-lived downtime.

*Other deployment strategies (blue-green, canary, etc.) can often provide a much better alternative to the RollingUpdate strategy. However, we are not taking them into account in this article since their implementation depends on the software used to deploy the application. That goes beyond the scope of this article*. 

>Here is a [great article](https://www.weave.works/blog/kubernetes-deployment-strategies) on the topic that we recommend and is well worth the read.

## Uniform replicas distribution across nodes

It is very important that you distribute Pods of the application across different nodes if you have multiple replicas of the application. To do so, **you can instruct your scheduler to avoid starting multiple Pods of the same Deployment on the same node**:

```yaml
affinity:
podAntiAffinity:
  preferredDuringSchedulingIgnoredDuringExecution:
  - podAffinityTerm:
      labelSelector:
        matchLabels:
          app: testapp
      topologyKey: kubernetes.io/hostname
```

It is better to use `preferredDuringSchedulingaffinity` instead of `requiredDuringScheduling`. The latter may render it impossible to start new Pods if the number of nodes required for the new Pods is larger than the number of nodes available. Still, the `requiredDuringScheduling` affinity might come in handy when the number of nodes and application replicas is known in advance and you need to be sure that two Pods will not end up on the same node.
